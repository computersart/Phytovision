{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb1419-5123-4e00-a963-6181901545c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (only installs if not already installed)\n",
    "# Run this cell if you have not already installed these libraries, it will download it to your local machine.\n",
    "# This will usually fix the ModuleNotFoundError in the cell below\n",
    "# If you already have them, You will see \"Requirements already satisfied\" and it will not do anything\n",
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision numpy matplotlib kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf417fa-ce2e-4809-a2ac-d6602bcc8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "import os\n",
    "import math\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0181ea3-fecb-4a14-9f75-2dc9cdd6ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from kagglehub\n",
    "path = kagglehub.dataset_download(\"kritikseth/fruit-and-vegetable-image-recognition\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52e47d-0d76-4f63-834e-b988167d7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #Resize images because ResNet18 needs 224x224 images\n",
    "    transforms.ToTensor(), #Convert to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Normalize for imagenet standards\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941b347-512f-4772-990c-68c85c559f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=os.path.join(path, \"train\"), transform=data_transforms) #Load train folder from dataset + transform\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(path, \"test\"), transform=data_transforms) #Load test folder from dataset + transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) #Shuffling to ensure randomness and prevent bias/overfitting\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) #Don't shuffle because it is a validation/test dataset to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4fee7-a113-4682-bf50-b96d80a5459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_columns = 4  # Adjust this for the number of columns\n",
    "\n",
    "# Display images in a grid\n",
    "classes = train_dataset.classes\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "class_images = {cls: [] for cls in classes}\n",
    "\n",
    "# Collect one sample image per class\n",
    "for img_path, label in train_dataset.samples:\n",
    "    class_name = classes[label]\n",
    "    if len(class_images[class_name]) < 1:  # Increase number (1) if you want to see more images from the class\n",
    "        class_images[class_name].append(img_path)\n",
    "\n",
    "# Calculate grid size\n",
    "num_classes = len(classes)\n",
    "num_rows = math.ceil(num_classes / num_columns)\n",
    "\n",
    "# Create the grid\n",
    "fig, axs = plt.subplots(num_rows, num_columns, figsize=(num_columns * 4, num_rows * 4))\n",
    "axs = axs.flatten()  # Flatten for easier indexing\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    if class_images[cls]:  # Check if the class has images\n",
    "        img_path = class_images[cls][0]  # Use the first image for simplicity\n",
    "        img = torchvision.io.read_image(img_path).permute(1, 2, 0).numpy() / 255.0  # Normalize\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(cls)\n",
    "\n",
    "# Turn off remaining axes\n",
    "for j in range(len(classes), len(axs)):\n",
    "    axs[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fd021-3f0b-4aab-a6a2-7c91da506bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f37744-3952-4fcd-b5d4-4b299c6d1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell to see if model can be trained with the help of GPU \n",
    "# Prints True/False depending on CUDA availability aswell as CUDA version and device name\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True or False\n",
    "print(torch.version.cuda)         # Should return CUDA version or None\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))  # Should display GPU name\n",
    "else:\n",
    "    print(\"PyTorch cannot locate a CUDA compatible device (NVIDIA GPU).\") # Error handling and potential solutions\n",
    "    print(\"The possibilities are:\")\n",
    "    print(\"- No CUDA compatible NVIDIA GPU.\")\n",
    "    print(\"- CUDA drivers are not properly installed.\")\n",
    "    print(\"- You are using a non-CUDA version of PyTorch.\")\n",
    "    print(\"Model will be trained using only the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c2f68-c50e-47bb-be3f-bd0b12070eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd0448-507e-4d35-9705-51206731552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe90d7c-0aa0-4f35-b736-1d1e8c35aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"PhytovisionModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c122b-56bd-4f7f-8b92-615a7099b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and testing accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64901c1f-ff9e-40fb-b9bc-14d92827603b",
   "metadata": {},
   "source": [
    "# Additional Testing \n",
    "## The cells below will perform indepth analysis to gain insight into the model's performance \n",
    "### (Some of these functions might not work correctly or produce errors at the moment, it is experimental and will be in working condition very soon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ba401-0048-4c9a-b145-83460008e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install scikit-learn ipywidgets pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5645809-fb3f-4673-be63-a131c0564438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=range(len(train_dataset.classes)))\n",
    "\n",
    "# Create a larger figure and adjust layout\n",
    "plt.figure(figsize=(12, 12))  # Adjust the size by increasing or decreasing\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)\n",
    "disp.plot(cmap=\"viridis\", xticks_rotation=45, ax=plt.gca())\n",
    "plt.tight_layout()  # Adjust layout to fit everything properly\n",
    "plt.show()\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html (base code sourced from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c768eb9-f614-428a-b5dd-2edacc961a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = [0] * len(train_dataset.classes)\n",
    "class_total = [0] * len(train_dataset.classes)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            class_correct[labels[i]] += c[i].item()\n",
    "            class_total[labels[i]] += 1\n",
    "\n",
    "for i in range(len(train_dataset.classes)):\n",
    "    print(f\"Accuracy of {train_dataset.classes[i]}: {100 * class_correct[i] / class_total[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea97b0-865e-44e3-96d9-898f30887d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "misclassified = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for i in range(len(labels)):\n",
    "            if predicted[i] != labels[i]:\n",
    "                misclassified.append((images[i].cpu(), labels[i].cpu(), predicted[i].cpu()))\n",
    "\n",
    "# Display a few misclassified images\n",
    "num_to_show = 5\n",
    "random.shuffle(misclassified)\n",
    "fig, axs = plt.subplots(1, num_to_show, figsize=(15, 5))\n",
    "\n",
    "for i in range(num_to_show):\n",
    "    img, true_label, pred_label = misclassified[i]\n",
    "    axs[i].imshow(img.permute(1, 2, 0).numpy())\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f\"True: {train_dataset.classes[true_label]}\\nPred: {train_dataset.classes[pred_label]}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05a203-446d-4fe2-bd27-b0af45d16060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load the trained model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)  # Adjust based on your dataset\n",
    "model.load_state_dict(torch.load(\"PhytovisionModel.pth\", map_location=torch.device('cpu')))  \n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing for the uploaded image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# UI Elements\n",
    "upload_button = widgets.FileUpload(accept='.jpg,.jpeg,.png', multiple=False)\n",
    "predict_button = widgets.Button(description=\"Predict\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Store uploaded image\n",
    "uploaded_image = None\n",
    "\n",
    "def on_upload_change(change):\n",
    "    \"\"\"Handles file upload and stores the image.\"\"\"\n",
    "    global uploaded_image\n",
    "\n",
    "    for file_name, file_info in upload_button.value.items():\n",
    "        uploaded_image = Image.open(io.BytesIO(file_info['content']))  # Store image\n",
    "        \n",
    "        # Display the uploaded image\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            display(uploaded_image)\n",
    "            print(\"Image uploaded! Click 'Predict' to analyze.\")\n",
    "\n",
    "def on_predict_click(b):\n",
    "    \"\"\"Handles prediction when 'Predict' button is clicked.\"\"\"\n",
    "    global uploaded_image\n",
    "\n",
    "    if uploaded_image is None:\n",
    "        with output:\n",
    "            print(\"Please upload an image first!\")\n",
    "        return\n",
    "\n",
    "    # Preprocess the image\n",
    "    input_tensor = preprocess(uploaded_image).unsqueeze(0)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        confidence = torch.softmax(outputs, dim=1)[0][predicted].item() * 100\n",
    "\n",
    "    # Display prediction\n",
    "    with output:\n",
    "        print(f\"Prediction: Class {predicted.item()}\")  # Update with class names if available\n",
    "        print(f\"Confidence: {confidence:.2f}%\")\n",
    "\n",
    "# Link events to functions\n",
    "upload_button.observe(on_upload_change, names='value')\n",
    "predict_button.on_click(on_predict_click)\n",
    "\n",
    "# Display the UI\n",
    "display(widgets.VBox([\n",
    "    widgets.Label(\"Upload an image of a fruit or vegetable:\"),\n",
    "    upload_button,\n",
    "    predict_button,  # Added the predict button\n",
    "    output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28e779-579d-4b65-af0a-42e6d43de8f9",
   "metadata": {},
   "source": [
    "Credits / Acknowledgements / Resources used in the creation of this project\n",
    "\n",
    "- Dataset: https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition/\n",
    "- PyTorch: [https://pytorch.org/](https://pytorch.org/) + Torchvision: [https://pytorch.org/vision/](https://pytorch.org/vision/)\n",
    "- PyTorch Tutorials\n",
    "- Various machine learning tutorials on YouTube\n",
    "- Machine learning subreddit: [https://www.reddit.com/r/learnmachinelearning/](https://www.reddit.com/r/learnmachinelearning/)\n",
    "\n",
    "\n",
    "I am grateful to my supervisor for his guidance and academic advice during the project development.\n",
    "# Not yet complete, the remaining sources will be added very soon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
